# Thoughts on reinforcement learning and transfer learning to tackle complex tasks

###Eugenio Culurciello, November 2016

## Introduction

It would be nice to be able to teach robots to do things for us: go fetch my keys, make me a sandwich, do the laundry. And we have dextrous robots that can perform [these tasks now](https://en.wikipedia.org/wiki/DARPA_Robotics_Challenge), but what is missing is their brain. And when we talk about brain we are talking about two issues:

- what architecture
- how to train it

We could let our robot explore the environment with little information about it, but it will take a long time to figure things out.

Obviously we would not want to wait for years to train our robot. We want it to learn fast and help us. Ideally we want to train it on YouTube video and by showing examples of what we want. We can call this 'transfer learning' because we need to transfer the knowledge we have to the machine.

When we learn a new task, we do not have to train our brain from a blank slate. Rather we have something that is already pre-trained, and often we follow simple instruction from others on how to perform the task.


We need and architecture and training that can support both.




## Q-Learning / Reinforcement Learning

Q-learning and DeepMind work on DQN showed how we can train a neural network to play video games by just looking at the screen and score. 



## Catch experiments:





